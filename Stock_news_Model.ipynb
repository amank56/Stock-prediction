{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset which we created earlier\n",
    "ds0= pd.read_csv(\"C:\\\\Dev\\\\mycode\\\\Ds_Apple.csv\")\n",
    "ds1= pd.read_csv(\"C:\\\\Dev\\\\stock_news_data\\\\Ds_Apple_04-26-2020.csv\")\n",
    "ds2= pd.read_csv(\"C:\\\\Dev\\\\stock_news_data\\\\Ds_Apple_04-28-2020.csv\")\n",
    "frames=[ds0,ds1,ds2]\n",
    "df=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Firm</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Label</th>\n",
       "      <th>Description</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>11/20/2006</td>\n",
       "      <td>Mac fans buzzing about expected Apple \"iPhone\"</td>\n",
       "      <td>1</td>\n",
       "      <td>SAN FRANCISCO  Reuters  The longrumored arriv...</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>12.352858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>12/13/2006</td>\n",
       "      <td>Apple's iTunes music sales collapses in H1: su...</td>\n",
       "      <td>1</td>\n",
       "      <td>AMSTERDAM  Reuters  Sales at Apples online mu...</td>\n",
       "      <td>12.564285</td>\n",
       "      <td>12.721429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>12/13/2006</td>\n",
       "      <td>Piper Jaffray disputes report of weak iTunes s...</td>\n",
       "      <td>1</td>\n",
       "      <td>NEW YORK  Reuters  Digital music sales surged...</td>\n",
       "      <td>12.564285</td>\n",
       "      <td>12.721429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Apple</td>\n",
       "      <td>12/15/2006</td>\n",
       "      <td>Apple files to delay annual report for option ...</td>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON  Reuters  Apple Computer Inc  AAPL...</td>\n",
       "      <td>12.717143</td>\n",
       "      <td>12.531428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>12/27/2006</td>\n",
       "      <td>Apple shares recover</td>\n",
       "      <td>1</td>\n",
       "      <td>BOSTON  Reuters  Apple Computer Inc shares fe...</td>\n",
       "      <td>11.164286</td>\n",
       "      <td>11.645715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Firm        Date  \\\n",
       "0           0  Apple  11/20/2006   \n",
       "1           1  Apple  12/13/2006   \n",
       "2           2  Apple  12/13/2006   \n",
       "3           3  Apple  12/15/2006   \n",
       "4           4  Apple  12/27/2006   \n",
       "\n",
       "                                           Headlines  Label  \\\n",
       "0     Mac fans buzzing about expected Apple \"iPhone\"      1   \n",
       "1  Apple's iTunes music sales collapses in H1: su...      1   \n",
       "2  Piper Jaffray disputes report of weak iTunes s...      1   \n",
       "3  Apple files to delay annual report for option ...      0   \n",
       "4                               Apple shares recover      1   \n",
       "\n",
       "                                         Description       Open      Close  \n",
       "0   SAN FRANCISCO  Reuters  The longrumored arriv...  12.200000  12.352858  \n",
       "1   AMSTERDAM  Reuters  Sales at Apples online mu...  12.564285  12.721429  \n",
       "2   NEW YORK  Reuters  Digital music sales surged...  12.564285  12.721429  \n",
       "3   WASHINGTON  Reuters  Apple Computer Inc  AAPL...  12.717143  12.531428  \n",
       "4   BOSTON  Reuters  Apple Computer Inc shares fe...  11.164286  11.645715  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1011 entries, 0 to 95\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1011 non-null   int64  \n",
      " 1   Firm         1011 non-null   object \n",
      " 2   Date         1011 non-null   object \n",
      " 3   Headlines    1011 non-null   object \n",
      " 4   Label        1011 non-null   int64  \n",
      " 5   Description  1011 non-null   object \n",
      " 6   Open         1011 non-null   float64\n",
      " 7   Close        1011 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 71.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#getting the details of data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the label\n",
    "y=df['Label']\n",
    "col_name='Headlines' #either 'Description' or Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the text of headline/Description\n",
    "\n",
    "# Remove all the special characters\n",
    "df[col_name]=df[col_name].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "\n",
    "# remove all single characters\n",
    "df[col_name]=df[col_name].map(lambda x: re.sub(r'\\s+[a-zA-Z]\\s+',' ',x))\n",
    "\n",
    "# Remove single characters from the start\n",
    "df[col_name]=df[col_name].map(lambda x: re.sub(r'\\^[a-zA-Z]\\s+',' ',x))\n",
    "\n",
    "#Substituting multiple spaces with single space\n",
    "df[col_name]=df[col_name].map(lambda x: re.sub(r'\\s+', ' ',x,flags=re.I))\n",
    "\n",
    "# Removing prefixed 'b'\n",
    "df[col_name]=df[col_name].map(lambda x: re.sub(r'^b\\s+', ' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#df['Description']= df['Description'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(df[col_name],y,test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_features=2500, min_df=7, max_df=0.8,stop_words='english',tokenizer=lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=0.8, max_features=2500, min_df=7,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=<function lemmatize_text at 0x000001888F1D6948>,\n",
      "                vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "count_train=count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  115  116  117  \\\n",
       "0      0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "672    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "673    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "674    0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "675    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "676    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "     118  119  120  121  122  123  124  \n",
       "0      0    0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "672    0    0    0    0    0    0    0  \n",
       "673    0    0    0    0    0    0    0  \n",
       "674    0    0    0    0    0    0    0  \n",
       "675    0    0    0    0    0    0    0  \n",
       "676    0    1    0    0    0    0    0  \n",
       "\n",
       "[677 rows x 125 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " 'aapl',\n",
       " 'ahead',\n",
       " 'alpha',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'antitrust',\n",
       " 'ban',\n",
       " 'battle',\n",
       " 'beat',\n",
       " 'big',\n",
       " 'board',\n",
       " 'book',\n",
       " 'buy',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'ceo',\n",
       " 'china',\n",
       " 'coinspeaker',\n",
       " 'com',\n",
       " 'company',\n",
       " 'cook',\n",
       " 'court',\n",
       " 'cut',\n",
       " 'data',\n",
       " 'deal',\n",
       " 'delay',\n",
       " 'disappoint',\n",
       " 'dividend',\n",
       " 'drop',\n",
       " 'earn',\n",
       " 'einhorn',\n",
       " 'eu',\n",
       " 'event',\n",
       " 'exclusive',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'factbox',\n",
       " 'fall',\n",
       " 'fight',\n",
       " 'finance',\n",
       " 'fool',\n",
       " 'forecast',\n",
       " 'google',\n",
       " 'growth',\n",
       " 'health',\n",
       " 'high',\n",
       " 'hit',\n",
       " 'instant',\n",
       " 'investors',\n",
       " 'investorsobserver',\n",
       " 'ipad',\n",
       " 'iphone',\n",
       " 'iphones',\n",
       " 'itunes',\n",
       " 'job',\n",
       " 'judge',\n",
       " 'know',\n",
       " 'launch',\n",
       " 'look',\n",
       " 'mac',\n",
       " 'make',\n",
       " 'market',\n",
       " 'microsoft',\n",
       " 'million',\n",
       " 'mini',\n",
       " 'mobile',\n",
       " 'motley',\n",
       " 'music',\n",
       " 'nasdaq',\n",
       " 'new',\n",
       " 'news',\n",
       " 'nokia',\n",
       " 'offer',\n",
       " 'options',\n",
       " 'order',\n",
       " 'outlook',\n",
       " 'patent',\n",
       " 'phone',\n",
       " 'plan',\n",
       " 'price',\n",
       " 'profit',\n",
       " 'quarter',\n",
       " 'record',\n",
       " 'report',\n",
       " 'result',\n",
       " 'return',\n",
       " 'rise',\n",
       " 'rule',\n",
       " 's',\n",
       " 'sale',\n",
       " 'sales',\n",
       " 'samsung',\n",
       " 'say',\n",
       " 'seek',\n",
       " 'sell',\n",
       " 'set',\n",
       " 'share',\n",
       " 'source',\n",
       " 'steve',\n",
       " 'stock',\n",
       " 'store',\n",
       " 'street',\n",
       " 'strong',\n",
       " 'sue',\n",
       " 'talk',\n",
       " 'target',\n",
       " 'tax',\n",
       " 'tech',\n",
       " 'time',\n",
       " 'trade',\n",
       " 'trial',\n",
       " 'u',\n",
       " 'unveil',\n",
       " 'view',\n",
       " 'win',\n",
       " 'work',\n",
       " 'yahoo']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>9</th>\n",
       "      <th>aapl</th>\n",
       "      <th>ahead</th>\n",
       "      <th>alpha</th>\n",
       "      <th>analysis</th>\n",
       "      <th>analyst</th>\n",
       "      <th>...</th>\n",
       "      <th>tech</th>\n",
       "      <th>time</th>\n",
       "      <th>trade</th>\n",
       "      <th>trial</th>\n",
       "      <th>u</th>\n",
       "      <th>unveil</th>\n",
       "      <th>view</th>\n",
       "      <th>win</th>\n",
       "      <th>work</th>\n",
       "      <th>yahoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  3  4  5  9  aapl  ahead  alpha  analysis  analyst  ...  tech  time  \\\n",
       "0    0  0  0  0  0     1      0      0         0        0  ...     0     0   \n",
       "1    0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "2    0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "3    0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "4    0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "..  .. .. .. .. ..   ...    ...    ...       ...      ...  ...   ...   ...   \n",
       "672  0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "673  0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "674  0  0  0  0  0     1      0      0         0        0  ...     0     0   \n",
       "675  0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "676  0  0  0  0  0     0      0      0         0        0  ...     0     0   \n",
       "\n",
       "     trade  trial  u  unveil  view  win  work  yahoo  \n",
       "0        0      0  0       0     0    0     0      0  \n",
       "1        0      0  0       0     0    0     0      0  \n",
       "2        0      0  0       0     0    0     0      0  \n",
       "3        0      0  0       0     0    0     0      0  \n",
       "4        0      0  0       0     0    0     0      0  \n",
       "..     ...    ... ..     ...   ...  ...   ...    ...  \n",
       "672      0      0  0       0     0    0     0      0  \n",
       "673      0      0  0       0     0    0     0      0  \n",
       "674      0      0  0       0     0    0     0      0  \n",
       "675      0      0  0       0     0    0     0      0  \n",
       "676      0      0  1       0     0    0     0      0  \n",
       "\n",
       "[677 rows x 125 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_train.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nb_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5449101796407185"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66,  93],\n",
       "       [ 59, 116]], dtype=int64)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1, 0.1)\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(count_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(count_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.5568862275449101\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.5568862275449101\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.5568862275449101\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.5538922155688623\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.5568862275449101\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.5568862275449101\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.5508982035928144\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.5508982035928144\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.5508982035928144\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.5508982035928144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "#Checking the performance with different alpha values\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(-6.35350009728881, 'battle'), (-6.35350009728881, 'offer'), (-5.948034989180646, 'expectations'), (-5.948034989180646, 'eye'), (-5.948034989180646, 'forecast'), (-5.948034989180646, 'investorsobserver'), (-5.948034989180646, 'know'), (-5.948034989180646, 'outlook'), (-5.948034989180646, 'phone'), (-5.948034989180646, 'rule'), (-5.948034989180646, 'u'), (-5.660352916728865, '4'), (-5.660352916728865, '9'), (-5.660352916728865, 'court'), (-5.660352916728865, 'deal'), (-5.660352916728865, 'exclusive'), (-5.660352916728865, 'iphones'), (-5.660352916728865, 'nokia'), (-5.660352916728865, 'rise'), (-5.660352916728865, 'strong')]\n",
      "1 [(-4.407589948233497, 'earn'), (-4.407589948233497, 'finance'), (-4.407589948233497, 's'), (-4.407589948233497, 'steve'), (-4.407589948233497, 'yahoo'), (-4.338597076746545, 'ceo'), (-4.338597076746545, 'china'), (-4.338597076746545, 'launch'), (-4.274058555608974, 'seek'), (-4.050915004294765, 'sales'), (-4.002124840125333, 'samsung'), (-3.9556048244904396, 'report'), (-3.86859344750081, 'say'), (-3.7885507398272735, 'new'), (-3.714442767673552, 'share'), (-3.714442767673552, 'stock'), (-3.5501397163822754, 'ipad'), (-3.4357293652045313, 'job'), (-3.3089776595653873, 'aapl'), (-2.887764194489084, 'iphone')]\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n",
    "\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5658682634730539\n",
      "[[ 57 102]\n",
      " [ 43 132]]\n"
     ]
    }
   ],
   "source": [
    "#with Tfidf\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2500, min_df=7, max_df=0.8, stop_words='english',use_idf=True)\n",
    "\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(X_train.values)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(tfidf_train,y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test,pred)\n",
    "print(score)\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0,1])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.5688622754491018\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.5658682634730539\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.5658682634730539\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.562874251497006\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.5598802395209581\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.5598802395209581\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.5598802395209581\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.5598802395209581\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.5568862275449101\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.5538922155688623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amank\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sources</th>\n",
       "      <td>0.614558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>0.578580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <td>0.536249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapl</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarter</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfidf\n",
       "sources  0.614558\n",
       "book     0.578580\n",
       "market   0.536249\n",
       "aapl     0.000000\n",
       "news     0.000000\n",
       "record   0.000000\n",
       "quarter  0.000000\n",
       "profit   0.000000\n",
       "price    0.000000\n",
       "phone    0.000000"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_vector_tfidfvectorizer=tfidf_train[2]\n",
    " \n",
    "# place tf-idf values in a pandas data frame\n",
    "df_temp = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df_temp=df_temp.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "df_temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(-5.704700368384229, 'sell'), (-5.679637171009755, 'outlook'), (-5.676576012462584, 'know'), (-5.669430227265, 'price'), (-5.624911186506288, 'expectations'), (-5.5771105276414845, 'phone'), (-5.530195277806578, 'investorsobserver'), (-5.5210099671894275, 'cuts'), (-5.503146711065383, 'time'), (-5.452596701207903, 'strong'), (-5.386945713502266, 'disappoint'), (-5.326976573079296, 'court'), (-5.310557468358194, 'eu'), (-5.310011694144957, 'return'), (-5.2833860945497895, 'deal'), (-5.27938928704308, 'nokia'), (-5.272123127398281, 'exclusive'), (-5.269868036132053, 'microsoft'), (-5.248841026163111, 'iphones'), (-5.223517516211487, 'music')]\n",
      "1 [(-4.447813565524789, 'million'), (-4.444946508884515, 'finance'), (-4.401587157237346, 'launch'), (-4.39036488090326, 'alpha'), (-4.39036488090326, 'seeking'), (-4.258633211363701, 'earnings'), (-4.254551555549038, 'ceo'), (-4.138096122398471, 'steve'), (-4.119769628283791, 'china'), (-4.045649522779904, 'sales'), (-3.948080250243085, 'stock'), (-3.891497114413987, 'report'), (-3.8454720951753503, 'samsung'), (-3.8032883776731663, 'new'), (-3.7275138223161104, 'says'), (-3.601683706237307, 'shares'), (-3.4777073852979576, 'aapl'), (-3.466499623444801, 'ipad'), (-3.280467230000546, 'jobs'), (-2.8836523673285943, 'iphone')]\n"
     ]
    }
   ],
   "source": [
    "#inspecting the model\n",
    "\n",
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n",
    "\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6167664670658682\n",
      "Precision: 0.6\n",
      "Recall: 0.8057142857142857\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "# https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python good example to implement it with lot of\n",
    "#details\n",
    "\n",
    "#import SVM\n",
    "from sklearn import svm\n",
    "# referring back to split dataset\n",
    "#X_train, X_test, y_train, y_test=train_test_split(df[col_name],y,test_size=0.33, random_state=53)\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear', C=1) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets - here we took the training dataset which is in vecotrized format by countvectorizer\n",
    "clf.fit(count_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(count_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
